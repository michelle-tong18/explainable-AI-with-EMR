{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import of packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import dotenv #load_dotenv, find_dotenv\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = #TODO 'path_to_your_project/env'\n",
    "dotenv.load_dotenv(env_path)\n",
    "\n",
    "API_KEY = os.environ.get('API_KEY')\n",
    "API_VERSION = os.environ.get('API_VERSION')\n",
    "RESOURCE_ENDPOINT = os.environ.get('RESOURCE_ENDPOINT')\n",
    "\n",
    "use_azure_active_directory = False\n",
    "\n",
    "if not use_azure_active_directory:\n",
    "    endpoint = os.environ[\"RESOURCE_ENDPOINT\"]\n",
    "    api_key = os.environ[\"API_KEY\"]\n",
    "\n",
    "    client = openai.AzureOpenAI(\n",
    "        azure_endpoint=endpoint,\n",
    "        api_key=api_key,\n",
    "        api_version=\"2023-09-01-preview\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=RESOURCE_ENDPOINT,\n",
    ")\n",
    "\n",
    "# client\n",
    "file_name = #TODO 'path_to_your_project/cohort_note_text_raw.csv'\n",
    "save_name = #TODO 'path_to_your_project/cohort_note_text_run1.csv'\n",
    "\n",
    "df = pd.read_csv(file_name)\n",
    "df = df[['patientdurablekey','deid_note_key','note_text']]\n",
    "\n",
    "def extract_impressions(report_text_orig):\n",
    "    # Replace newlines with spaces\n",
    "    report_text = report_text_orig.replace('\\n', ' ').strip()\n",
    "    # Replace multiple spaces with a single space\n",
    "    report_text = re.sub(r'\\s+', ' ', report_text)\n",
    "    \n",
    "    patterns = [\n",
    "        r\"(FINDINGS.*?)(?=Report dictated by)\",  # FINDINGS section ending before \"Report dictated by\"\n",
    "        r\"(FINDINGS.*?)(?=END OF IMPRESSION)\",   # FINDINGS section ending before \"END OF IMPRESSION\"\n",
    "        r\"(IMPRESSION.*?)(?=END OF IMPRESSION)\", # IMPRESSION section ending before \"END OF IMPRESSION\"\n",
    "        r\"(.*?)(?=END OF IMPRESSION)\",                # Match just ends with \"END OF IMPRESSION\" (if nothing else is found)\n",
    "        r\"(.*?)(?=Report dictated by)\",               # Match just ends with \"Report dictated by\" (if nothing else is found)\n",
    "        r\"(FINDINGS:.*?)(.*?)\",                       # Match just starts with \"FINDINGS\" (if nothing else is found)\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, report_text, flags=re.DOTALL | re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(0)\n",
    "    return \"Impressions section not found.\"\n",
    "\n",
    "# Extract the impressions section\n",
    "df['impressions'] = df['note_text'].apply(extract_impressions)\n",
    "\n",
    "# Remove the word \"significant\" from all impressions\n",
    "df['impressions'] = df['impressions'].str.replace(r'\\bsignificant\\b', '', case=False, regex=True)\n",
    "\n",
    "df_missing = df[df['impressions']=='Impressions section not found.']\n",
    "print('n missing',len(df_missing))\n",
    "for note in df_missing['note_text'][0:min(len(df_missing),3)]:\n",
    "    # Replace newlines with spaces\n",
    "    report_text = note.replace('\\n', ' ').strip()\n",
    "    # Replace multiple spaces with a single space\n",
    "    report_text = re.sub(r'\\s+', ' ', report_text)\n",
    "    print(report_text)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pathology dictionaries, one for level-wise pathologies and one for overall pathologies. Then, initiate output columns with pathology names and normalized levels. Define Prompt base and prompt task, for level-wise pathologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_store = {\n",
    "    \"PathologiesLevel\": {\n",
    "        1: {\"name\": \"Endplate Changes\",\n",
    "            \"abbr\": \"endplate\",\n",
    "            \"loc\": \"level\",\n",
    "            \"syn\": \"Modic changes, Modic endplate changes, fibrovascular degenerative changes, fibrovascular changes, fibrofatty degenerative changes, \\\n",
    "                    fibrofatty changes, endplate sclerosis, endplate degeneration, endplate irregularity, endplate irregularities, \\\n",
    "                    endplate defect, endplate defects, Schmorl's node, schmorls node\" \n",
    "            },\n",
    "        2: {\"name\": \"Disc Pathology\",\n",
    "            \"abbr\": \"disc\",\n",
    "            \"loc\": \"level\",\n",
    "            \"syn\": \"disc bulge, disc bulging, disc protrusion, disc extrusion, annular fissure, disc tear, annular tear, sequester, disc herniation\" \n",
    "            },\n",
    "        3: {\"name\": \"Spinal Canal Stenosis\",\n",
    "            \"abbr\": \"scs\",\n",
    "            \"loc\": \"level\",\n",
    "            \"syn\": \"spinal canal stenosis, spinal canal narrowing, central canal stenosis, central canal narrowing, canal stenosis, canal narrowing\"\n",
    "            },\n",
    "        4: {\"name\": \"Facet Joint Arthropathy\",\n",
    "            \"abbr\": \"fj\",\n",
    "            \"loc\": \"level\",\n",
    "            \"syn\": \"facet joint degeneration, facet joint arthropathy, facet degeneration, facet arthropathy, facet hypertropthy\"\n",
    "            }\n",
    "    }, \n",
    "    \"PathologiesLevelSide\": {\n",
    "        1: {\"name\": \"Lateral Recess Stenosis\",\n",
    "            \"abbr\": \"lrs\",\n",
    "            \"loc\": \"level_side\",\n",
    "            \"syn\": \"lateral recess stenosis, subarticular recess stenosis, recess stenosis, lateral recess narrowing, subarticular recess narrowing, \\\n",
    "                    recess narrowing, narrowing of lateral recess, narrowing of subarticular recess, stenosis of lateral recess, \\\n",
    "                    stenosis of subarticular recess, effacement of lateral recess, effacement of subarticular recess\"\n",
    "            },\n",
    "        2: {\"name\": \"Foraminal Stenosis\",\n",
    "            \"abbr\": \"fs\",\n",
    "            \"loc\": \"level_side\",\n",
    "            \"syn\": \"neural foraminal stenosis, neural foraminal narrowing, neural foraminal effacement, neural foraminal nerve root affection, \\\n",
    "                    foraminal stenosis, foraminal narrowing, foraminal effacement, foraminal nerve root affection, neuroforaminal stenosis, \\\n",
    "                    neuroforaminal narrowing, neuroforaminal effacement, neuroforaminal nerve root affection,\"\n",
    "            },\n",
    "    },\n",
    "    \"PathologiesPatient\": {\n",
    "        1: {\"name\": \"Sacroiliac Joint\",\n",
    "            \"abbr\": \"sij\",\n",
    "            \"loc\": \"patient\",\n",
    "            \"syn\": \"sacroiliac joint degeneration, degeneration of sacroiliac joints, sacro-iliac joint degeneration, degeneration of sacro-iliac joints, \\\n",
    "                    SIJ degeneration, degeneration of SIJ, degenerative changes of the sacroiliac joints, degenerative changes of the sacro-iliac joints\"\n",
    "                    \n",
    "            },  \n",
    "        2: {\"name\": \"Olisthesis\",\n",
    "            \"abbr\": \"olisth\",\n",
    "            \"loc\": \"patient\",\n",
    "            \"syn\": \"anterolisthesis, retrolisthesis, spondylolysis, pseudo-anterolisthesis, pseudo-retrolisthesis, vertebral displacement\"\n",
    "            },\n",
    "        3: {\"name\": \"Curvature\",\n",
    "            \"abbr\": \"curv\",\n",
    "            \"loc\": \"patient\",\n",
    "            \"syn\": \"scoliosis, levoconvex curvature, dextroconvex curvature, leftward convex curvature, rightward convex curvature, levocurvature, \\\n",
    "                    dextrocurvature, levoscoliosis, dextroscoliosis, S-shaped curvature\"\n",
    "            },\n",
    "        4: {\"name\": \"Fracture\",\n",
    "            \"abbr\": \"frac\",\n",
    "            \"loc\": \"patient\",\n",
    "            \"syn\": \"fracture, osteoporotic fracture, osteoporotic deformation, wedge deformity\"\n",
    "            }   \n",
    "    },\n",
    "        \"OutputFormats\": {\n",
    "        \"level\":{\n",
    "            \"loc\":\"level\",\n",
    "            \"output\": \"As a result, give me a list with exactly 20 entries, grouped by pathology. It must contain five entries for each pathology, \\\n",
    "                      one for each of the five vertebral levels (L1-2 to L5-S1). For endplate changes, give only entries of 0 (for pathology absent) \\\n",
    "                      or 1 (for pathology present). For disc pathology, facet joint arthropthy, and spinal canal stenosis the entry must be 0 if \\\n",
    "                      there is no spinal canal stenosis, 1 if it is described as mild, 2 if it is described as moderate of no further qualification \\\n",
    "                      of stenosis extent is given, and 3 if it is described as severe. Entries in the list must always adhere to this format. \\\n",
    "                      Here are three example entries: Endplate Changes L1-L2: 0, Disc Pathology L5-S1: 1, Spinal Canal Stenosis: 3. \\\n",
    "                      Ignore levels named ALPHANUMERICID. End the list with 'END OF LIST'.\"\n",
    "        },\n",
    "        \"level_side\":{\n",
    "            \"loc\":\"level_side\",\n",
    "            \"output\": \"As a result, give me a list with exactly 20 entries, grouped by pathology; each entry must be on a new line, do not use \\\n",
    "                      commas to separate entries. It must contain ten entries for each pathology, two for each of the five vertebral levels \\\n",
    "                      (L1-2 to L5-S1), one for the right and one for the left side at each level. The entry must be 0 if there is no mention of a \\\n",
    "                      pathology at this level, 1 if the pathology is described as mild, 2 if it is described as moderate or there is no further \\\n",
    "                      qualification of the extent of the pathology, and 3 if it is described as severe. Entries in the list must always adhere to \\\n",
    "                      this format. Here are two example entries: Foraminal Stenosis L1-L2 right: 2, Lateral Recess Stenosis L5-S1 left: 0. Ignore \\\n",
    "                      levels named ALPHANUMERICID. End the list with 'END OF LIST'.\"\n",
    "        },\n",
    "        \"patient\":{\n",
    "            \"loc\":\"patient\",\n",
    "            \"output\": \"As a result, give me a list with exactly 4 entries. It must contain one entry for each pathology with corresponding entries \\\n",
    "                       of either 1 or 0. Entries in the list must always adhere to this format. Here are two example entries: Sacroiliac joint: 0, \\\n",
    "                       Fracture: 1. Ignore levels named ALPHANUMERICID. End the list with 'END OF LIST'.\"\n",
    "        },\n",
    "    },\n",
    "    \"InterpretationGuidance\": {\n",
    "        \"bilateral_changes\":{\n",
    "            \"patterns\": [\"left greater than right\", \"right greater than left\", \"bilateral\"],\n",
    "            \"guidance\": \"Consider phrases like 'bilateral','left greater than right' or 'right greater than left' as presence of changes on both \\\n",
    "                        sides. Please apply this rule strictly in your interpretation.\"\n",
    "        },\n",
    "        \"segment_localization\":{\n",
    "            \"patterns\": [\"superior endplate\", \"inferior endplate\"],\n",
    "            \"guidance\": \"If a change is described as localized at the superior endplate, attribute it to the level above this vertebral body (e.g. \\\n",
    "                        superior endplate L2 belongs to the level L1-L2); conversely the inferior endplate belongs to the segment of below its \\\n",
    "                        vertebral body (e.g. inferior endplate L3 belongs to the Level L3-L4).\"\n",
    "        },\n",
    "        \"multilevel\":{\n",
    "            \"patterns\": [\"multilevel\"],\n",
    "            \"guidance\": \"If a pathology is described as 'multilevel' assume it is present in all vertebral levels.\"\n",
    "        },\n",
    "        \"desiccation\":{\n",
    "            \"patterns\": [\"desiccation\"],\n",
    "            \"guidance\": \"Do not consider desiccation or darkening of discs a pathology.\"\n",
    "        },\n",
    "        \"heightloss\":{\n",
    "            \"patterns\": [\"height\"],\n",
    "            \"guidance\": \"Do not consider height loss of a disc a pathology.\"\n",
    "        },\n",
    "        \"straight\":{\n",
    "            \"patterns\": [\"straightening\"],\n",
    "            \"guidance\": \"Do not consider straightening or loss of lumbar lordosis a pathology.\"\n",
    "        },\n",
    "        \"significant\":{\n",
    "            \"patterns\": [\"significant\"],\n",
    "            \"guidance\": \"Consider pathologies described as 'not significant' as not present.\"\n",
    "        },\n",
    "        \"without\":{\n",
    "            \"patterns\": [\"without\"],\n",
    "            \"guidance\": \"Consider pathologies described as 'without' as not present.\"\n",
    "        },\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize output columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_convert_to_column_name(level, abbr, side=None):\n",
    "    normalized_level = level.lower().split('-')[0].split('l')[1]\n",
    "    if side:\n",
    "            return f\"gpt_{abbr}_lvl_l{normalized_level}_{side}\"\n",
    "    else:\n",
    "        return f\"gpt_{abbr}_lvl_l{normalized_level}\"\n",
    "\n",
    "def initialize_dataframe_columns(data_store, df):\n",
    "    # Initialize columns for level pathologies\n",
    "    if \"PathologiesLevel\" in data_store:\n",
    "        for pathology_id, pathology_info in data_store[\"PathologiesLevel\"].items():\n",
    "            abbr = pathology_info[\"abbr\"]\n",
    "            for level in [\"l1\", \"l2\", \"l3\", \"l4\", \"l5\"]:\n",
    "                column_name = normalize_and_convert_to_column_name(level, abbr)\n",
    "                if column_name not in df.columns:\n",
    "                    df[column_name] = pd.NA\n",
    "\n",
    "    # Initialize columns for level_side pathologies\n",
    "    if \"PathologiesLevelSide\" in data_store:\n",
    "        for pathology_id, pathology_info in data_store[\"PathologiesLevelSide\"].items():\n",
    "            abbr = pathology_info[\"abbr\"]\n",
    "            for level in [\"l1\", \"l2\", \"l3\", \"l4\", \"l5\"]:\n",
    "                for side in [\"left\", \"right\"]:\n",
    "                    column_name = normalize_and_convert_to_column_name(level, abbr, side)\n",
    "                    if column_name not in df.columns:\n",
    "                        df[column_name] = pd.NA\n",
    "\n",
    "    # Initialize columns for patient-level pathologies\n",
    "    if \"PathologiesPatient\" in data_store:\n",
    "        for pathology_id, pathology_info in data_store[\"PathologiesPatient\"].items():\n",
    "            abbr = pathology_info[\"abbr\"]\n",
    "            column_name = f\"gpt_{abbr}_patient\"\n",
    "            if column_name not in df.columns:\n",
    "                df[column_name] = pd.NA\n",
    "    return df\n",
    "\n",
    "df = initialize_dataframe_columns(data_store, df)\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic prompting with interpretation guidance depending on specific wordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_guidance_if_needed(report_text, base_prompt, data_store):\n",
    "    appended_guidances = set()  # Set to keep track of appended guidances\n",
    "    \n",
    "    for guidance in data_store[\"InterpretationGuidance\"].values():\n",
    "        for pattern in guidance[\"patterns\"]:\n",
    "            if pattern.lower() in report_text.lower():\n",
    "                # If the pattern is found in the report and guidance not already added, append the guidance to the prompt\n",
    "                if guidance[\"guidance\"] not in appended_guidances:\n",
    "                    base_prompt += f\"\\n\\n[Guidance: {guidance['guidance']}]\"\n",
    "                    appended_guidances.add(guidance[\"guidance\"])\n",
    "                break  # Break if at least one pattern matches to avoid duplicate guidance within the same category\n",
    "\n",
    "    return base_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_level_output(line, pathology_abbr):\n",
    "    # Adjusting for potential trailing commas and spaces\n",
    "    line = line.rstrip(\", \")\n",
    "    match = re.match(r\"(.+?) (L\\d+(-S\\d+)?)\\s*:\\s*(\\d+)\", line, re.IGNORECASE)\n",
    "    if match:\n",
    "        _, level, _, presence = match.groups()\n",
    "        # Adjusting level normalization to handle \"L5-S1\"\n",
    "        normalized_level = \"\".join(filter(str.isdigit, level))\n",
    "        column_name = f\"gpt_{pathology_abbr}_lvl_l{normalized_level}\"\n",
    "        return column_name, int(presence)\n",
    "    return None, None\n",
    "\n",
    "def parse_level_side_output(line, pathology_abbr):\n",
    "    line = line.rstrip(\", \")\n",
    "    match = re.match(r\"(.+?)\\s+(L\\d+(-S\\d+)?)\\s*(left|right)?\\s*:\\s*(\\d+)\", line, re.IGNORECASE)\n",
    "    if match:\n",
    "        _, level, _, side, presence = match.groups()\n",
    "        normalized_level = \"\".join(filter(str.isdigit, level))\n",
    "        side_suffix = side.lower()\n",
    "        column_name = f\"gpt_{pathology_abbr}_lvl_l{normalized_level}_{side_suffix}\"\n",
    "        return column_name, int(presence)\n",
    "    return None, None\n",
    "\n",
    "def parse_and_update_patient_output(analysis_result, data_store, df, index):\n",
    "    # Split the output into individual pathology reports\n",
    "    pathology_reports = analysis_result.split(', ')\n",
    "    for report in pathology_reports:\n",
    "        # Attempt to match each report to the expected format\n",
    "        match = re.match(r\"(.+?): (\\d)\", report)\n",
    "        if match:\n",
    "            pathology_name, presence_str = match.groups()\n",
    "            presence = int(presence_str)\n",
    "\n",
    "            # Find the corresponding abbreviation and column name for the pathology\n",
    "            for pathology_info in data_store[\"PathologiesPatient\"].values():\n",
    "                if pathology_name.lower() == pathology_info[\"name\"].lower():\n",
    "                    abbr = pathology_info[\"abbr\"]\n",
    "                    column_name = f\"gpt_{abbr}_patient\"\n",
    "\n",
    "                    # Update the DataFrame\n",
    "                    df.at[index, column_name] = presence\n",
    "                    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query VERSA for level-wise pathologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for index, row in df.iterrows():\n",
    "        report_text = row['impressions']\n",
    "        pathologies_info = [f\"{info['name']} ({info['abbr']})\" for info in data_store[\"PathologiesLevel\"].values()]\n",
    "        prompt_info = \", \".join(pathologies_info)\n",
    "        output_instruction = data_store[\"OutputFormats\"][\"level\"][\"output\"]\n",
    "        specific_prompt = f\"Given the following pathologies: {prompt_info}, {output_instruction}\\n\\nReport: {report_text}\\n\\n\"\n",
    "        enhanced_prompt = append_guidance_if_needed(report_text, specific_prompt, data_store)\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": enhanced_prompt},\n",
    "                {\"role\": \"system\", \"content\": \"You are a medical expert, confident in the interpretation of radiology reports; \\\n",
    "                                              you do not assume the presence of a pathology if it is not identified.\"}\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "            max_tokens=500,\n",
    "            top_p=1.0,\n",
    "            frequency_penalty=0.0,\n",
    "            presence_penalty=0.0,\n",
    "            stop=[\"END OF LIST\"]\n",
    "        )\n",
    "        analysis_result = response.choices[0].message.content.strip()\n",
    "        \n",
    "        lines = analysis_result.strip().split('\\n')\n",
    "        for line in lines:\n",
    "            parts = line.split(': ')\n",
    "            if len(parts) == 2:\n",
    "                pathology_with_level, presence_str = parts\n",
    "                presence = int(presence_str.strip().rstrip(','))\n",
    "    \n",
    "                match = re.match(r\"(.+?) (L\\d+-[LS]?\\d+)\", pathology_with_level)\n",
    "                if match:\n",
    "                    pathology_name, level = match.groups()\n",
    "    \n",
    "                    for pathology_info in data_store[\"PathologiesLevel\"].values():\n",
    "                        if pathology_name.lower() == pathology_info[\"name\"].lower():\n",
    "                            abbr = pathology_info[\"abbr\"]\n",
    "                            column_name = normalize_and_convert_to_column_name(level, abbr)\n",
    "                            df.at[index, column_name] = presence\n",
    "                            break\n",
    "    \n",
    "        #Every \"N\" subjects save the dataframe. The modulo operator returns the remainder after division\n",
    "        if (index % 50) == 0:\n",
    "            df.to_csv(save_name, index=False)\n",
    "            print(index, 'saved')\n",
    "except Exception as e:\n",
    "    print(index)\n",
    "    print(e)\n",
    "\n",
    "df.to_csv(save_name, index=False)\n",
    "save_backup_name = os.path.dirname(save_name)+os.path.basename(save_name).replace('.csv','_levelwise.csv')\n",
    "df.to_csv(save_backup_name, index=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query VERSA for level- and side-wise pathologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for index, row in df[:].iterrows():\n",
    "        report_text = row['impressions']\n",
    "        # Extract pathology names and abbreviations from PathologiesLevelSide\n",
    "        pathologies_info = [f\"{info['name']} ({info['abbr']})\" for info in data_store[\"PathologiesLevelSide\"].values()]\n",
    "        prompt_info = \", \".join(pathologies_info)\n",
    "        \n",
    "        # Use the level_side-specific output instruction\n",
    "        output_instruction = data_store[\"OutputFormats\"][\"level_side\"][\"output\"]\n",
    "        specific_prompt = f\"Given the following pathologies: {prompt_info}, {output_instruction}\\n\\nReport: {report_text}\\n\\n\"\n",
    "        enhanced_prompt = append_guidance_if_needed(report_text, specific_prompt, data_store)\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": enhanced_prompt},\n",
    "                {\"role\": \"system\", \"content\": \"You are a medical expert, confident in the interpretation of radiology reports.\"}\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "            max_tokens=500,\n",
    "            top_p=1.0,\n",
    "            frequency_penalty=0.0,\n",
    "            presence_penalty=0.0,\n",
    "            stop=[\"END OF LIST\"]\n",
    "        )\n",
    "        analysis_result = response.choices[0].message.content.strip()\n",
    "    \n",
    "       \n",
    "    \n",
    "        lines = analysis_result.strip().split('\\n')\n",
    "        for line in lines:\n",
    "            parts = line.split(': ')\n",
    "            if len(parts) == 2:\n",
    "                pathology_with_level_side, presence_str = parts\n",
    "                presence = int(presence_str.strip().rstrip(','))\n",
    "    \n",
    "                match = re.match(r\"(.+?) (L\\d+-[LS]?\\d+) (left|right)\", pathology_with_level_side)\n",
    "                if match:\n",
    "                    pathology_name, level, side = match.groups()\n",
    "    \n",
    "                    for pathology_info in data_store[\"PathologiesLevelSide\"].values():\n",
    "                        if pathology_name.lower() == pathology_info[\"name\"].lower():\n",
    "                            abbr = pathology_info[\"abbr\"]\n",
    "                            # Adjusting the function to include side information\n",
    "                            column_name = normalize_and_convert_to_column_name(level, abbr, side)\n",
    "                            df.at[index, column_name] = presence\n",
    "                            break\n",
    "        #Every \"N\" subjects save the dataframe. The modulo operator returns the remainder after division\n",
    "        if (index % 50) == 0:\n",
    "            df.to_csv(save_name, index=False)\n",
    "            print(index, 'saved')\n",
    "            \n",
    "except Exception as e:\n",
    "    print(index)\n",
    "    print(e)\n",
    "\n",
    "df.to_csv(save_name, index=False)\n",
    "save_backup_name = os.path.dirname(save_name)+os.path.basename(save_name).replace('.csv','_levelsidewise.csv')\n",
    "df.to_csv(save_backup_name, index=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query VERSA for patient  pathologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for index, row in df[:].iterrows():\n",
    "        report_text = row['impressions']\n",
    "        # Extract pathology names and abbreviations from PathologiesPatient\n",
    "        pathologies_info = [f\"{info['name']} ({info['abbr']})\" for info in data_store[\"PathologiesPatient\"].values()]\n",
    "        prompt_info = \", \".join(pathologies_info)\n",
    "        \n",
    "        # Use the patient-specific output instruction\n",
    "        output_instruction = data_store[\"OutputFormats\"][\"patient\"][\"output\"]\n",
    "        specific_prompt = f\"Given the following pathologies: {prompt_info}, {output_instruction}\\n\\nReport: {report_text}\\n\\n\"\n",
    "        enhanced_prompt = append_guidance_if_needed(report_text, specific_prompt, data_store)\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": enhanced_prompt},\n",
    "                {\"role\": \"system\", \"content\": \"You are a medical expert, confident in the interpretation of radiology reports.\"}\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "            max_tokens=500,\n",
    "            top_p=1.0,\n",
    "            frequency_penalty=0.0,\n",
    "            presence_penalty=0.0,\n",
    "            stop=[\"END OF LIST\"]\n",
    "        )\n",
    "        analysis_result = response.choices[0].message.content.strip()\n",
    "        parse_and_update_patient_output(analysis_result, data_store, df, index)\n",
    "\n",
    "        #Every \"N\" subjects save the dataframe. The modulo operator returns the remainder after division\n",
    "        if (index % 50) == 0:\n",
    "            df.to_csv(save_name, index=False)\n",
    "            print(index, 'saved')\n",
    "            \n",
    "except Exception as e:\n",
    "    print(index)\n",
    "    print(e)\n",
    "\n",
    "df.to_csv(save_name, index=False)\n",
    "save_backup_name = os.path.dirname(save_name)+os.path.basename(save_name).replace('.csv','_patientwise.csv')\n",
    "df.to_csv(save_backup_name, index=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('end of script')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
